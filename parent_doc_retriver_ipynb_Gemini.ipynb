{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8660uyxO_V4",
        "outputId": "0f6b382e-57d2-4a07-fdbf-7ac77999ba66"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain huggingface_hub openai tiktoken pypdf\n",
        "!pip -q install google-generativeai faiss-cpu chromadb unstructured\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install -U FlagEmbedding\n",
        "!pip install langchain-openai\n",
        "!pip -q install langchain_community tiktoken langchainhub chromadb langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jURZBfa9PVzT"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"]=\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIDEGSxpPmDH",
        "outputId": "ab4a11ab-6974-48b5-b9ca-1d97408b7617"
      },
      "outputs": [],
      "source": [
        "# prompt: write code to mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBlozxYfRH8z"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLx-YiuYRR5v"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "## Text Splitting & Docloader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C2LmZfuRXr7",
        "outputId": "8eca97d6-7644-4723-f481-33b5196cae99"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -U langchain-huggingface\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqDqqdmyRdBy",
        "outputId": "47ff85ae-9716-4ba5-e9e8-e2369d506e5e"
      },
      "outputs": [],
      "source": [
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}#for cosine similarity\n",
        "hf = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbd74XTJRhu_"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\n",
        "    \"/content/comments_new.docx_20241223_174156_0000.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfCt5URXR4G1",
        "outputId": "4577cd22-affd-46d4-87f5-4f26b534ca3a"
      },
      "outputs": [],
      "source": [
        "docs = loader.load()\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RtXzjbMSHEy",
        "outputId": "ffba692e-2a5a-47f1-d224-8f12dc5b42f4"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN9KddZFSbcw"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqtrWx30Ive",
        "outputId": "86620091-399a-40ee-ba75-51013107061f"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-chroma\n",
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwqoaZmlSlBQ"
      },
      "source": [
        "retrieving of complete/full document rather than in chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ22D3ESSjIV"
      },
      "outputs": [],
      "source": [
        "# This text splitter is used to create the child documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"full_documents\", embedding_function=hf\n",
        ")\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()\n",
        "retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itlbJ4JXS3z3"
      },
      "outputs": [],
      "source": [
        "retriever.add_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVuPlFOmS84Q",
        "outputId": "ec79885c-b627-45b7-e25d-6febb36823b2"
      },
      "outputs": [],
      "source": [
        "len(list(store.yield_keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4nR6uksTF_q"
      },
      "outputs": [],
      "source": [
        "sub_docs= vectorstore.similarity_search(\"what is the common complaint\",k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTMAnzWNTNz2",
        "outputId": "0bf780aa-55eb-4765-edd0-e5f84ba4fc07"
      },
      "outputs": [],
      "source": [
        "len(sub_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDBXD4n-TVTG",
        "outputId": "ce23a9a8-16a4-4bd6-cc7b-db19c29fe1d2"
      },
      "outputs": [],
      "source": [
        "print(sub_docs[1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P3gfUddTn1h"
      },
      "outputs": [],
      "source": [
        "rd=retriever.invoke(\"what is the common complaint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1879xVPNTwBH",
        "outputId": "2fa58b7d-938d-478c-dab3-9d3220447ce3"
      },
      "outputs": [],
      "source": [
        "len(rd[1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QxOabbDT4my",
        "outputId": "06908ced-a257-4648-be62-37a28529de14"
      },
      "outputs": [],
      "source": [
        "print(rd[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp5OJwLaUCJx"
      },
      "source": [
        "retrieving larger chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMjFVFTnT6nq"
      },
      "outputs": [],
      "source": [
        "# This text splitter is used to create the parent documents\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "# This text splitter is used to create the child documents\n",
        "# It should create documents smaller than the parent\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"split_parents\", embedding_function=hf\n",
        ")\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1XB6q-QUGUL"
      },
      "outputs": [],
      "source": [
        "chunk_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rImE7W9VUKwB"
      },
      "outputs": [],
      "source": [
        "chunk_retriever.add_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ng21gwUShV",
        "outputId": "27c0213f-d43a-4b1f-ffdb-28611263624b"
      },
      "outputs": [],
      "source": [
        "len(list(store.yield_keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-p3JWcMUYZC"
      },
      "outputs": [],
      "source": [
        "sub_docs= vectorstore.similarity_search(\"what is the common complaint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMKa9KlwUfjc",
        "outputId": "b0cd520b-290a-47c1-efed-c55d16585317"
      },
      "outputs": [],
      "source": [
        "print(sub_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6GXCnr6Uq7y",
        "outputId": "1e9d1f52-2376-4d7b-82ae-68b030b473d0"
      },
      "outputs": [],
      "source": [
        "len(sub_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sG976KAUuil"
      },
      "outputs": [],
      "source": [
        "rd=retriever.invoke(\"what is the common complaint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSEcWSAWU5xS",
        "outputId": "1747758a-20aa-43c3-b16c-0b4503d575c6"
      },
      "outputs": [],
      "source": [
        "len(rd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyGl09QUU7x7",
        "outputId": "fe9dd595-5b6d-47ea-f0d2-76ad8faba9f7"
      },
      "outputs": [],
      "source": [
        "len(rd[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNtnoavmVA3d",
        "outputId": "03a499b8-a587-4c14-c6d1-f3c86d5e92f0"
      },
      "outputs": [],
      "source": [
        "print(rd[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hUUbCboVSBS"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Answer the question based only on the following context\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template),])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BupZmGJe7L--"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STDnpRG57QHx"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfUM2sBbVYjb"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=model,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=chunk_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-PHwDfuVdIV",
        "outputId": "93efd107-79b1-424e-b1b3-7c86d899246f"
      },
      "outputs": [],
      "source": [
        "query=\"what is the common complaint\"\n",
        "qa.invoke(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYlxiHHTVoln"
      },
      "source": [
        "dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7opG7rmgVp3M",
        "outputId": "8f4687e6-eec7-47c7-aa77-d0b829a66bf7"
      },
      "outputs": [],
      "source": [
        "!pip install -U dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ7sdzCMV9vr"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "from dsp.utils import deduplicate\n",
        "#turbo=dspy.Together(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",api_key=\"6c818e6aeda3d7c5ce440139ecd84a9b25941be08d0ad05e690d5ff8c528c61a\")\n",
        "gemini = dspy.Google(\"gemini-1.5-pro\",\n",
        "                         api_key=\"AIzaSyABntcsOzYGUBs0-MP66f6yoxXbmKaaUbs\",\n",
        "                         temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBr1dXv3-ayU"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_-7WyzVWX0q"
      },
      "outputs": [],
      "source": [
        "retriever=chunk_retriever\n",
        "class ChromaRetriever:\n",
        "    def __init__(self, retriever):\n",
        "        self.retriever = retriever\n",
        "\n",
        "    def __call__(self, query, k=5):\n",
        "        results = self.retriever.get_relevant_documents(query)\n",
        "        # Format results to include a `long_text` attribute\n",
        "        return [\n",
        "            {\"long_text\": result.page_content, \"metadata\": result.metadata}\n",
        "            for result in results\n",
        "        ]\n",
        "\n",
        "# Instantiate your retriever\n",
        "chroma_retriever = ChromaRetriever(retriever)\n",
        "\n",
        "# Configure DSPy to use the ChromaRetriever for RM\n",
        "dspy.settings.configure(lm=gemini, max_tokens=1024)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "DwKBG0VgWchl",
        "outputId": "fd27c96e-878d-4fdc-9348-a330784c543a"
      },
      "outputs": [],
      "source": [
        "print(dspy.settings.enable_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "MfvTvtKmW2Mx",
        "outputId": "cbd87c76-2d94-4699-bd21-7b7980771265"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "from dspy import Signature, InputField, OutputField, Module, ChainOfThought\n",
        "\n",
        "class GenerateQuery(Signature):\n",
        "    context = InputField(desc=\"may contain relevant facts\")\n",
        "    question = InputField()\n",
        "    query = OutputField()\n",
        "\n",
        "class GenerateAnswer(Signature):\n",
        "    context = InputField(desc=\"contains parent documents\")\n",
        "    question = InputField()\n",
        "    answer = OutputField(desc=\"a concise and relevant response\")\n",
        "\n",
        "class ParentDocumentRetriever(Module):\n",
        "    def __init__(self, retriever, max_docs=5):\n",
        "        super().__init__()\n",
        "        self.generate_query = ChainOfThought(GenerateQuery)\n",
        "        self.retriever = retriever\n",
        "        self.generate_answer = ChainOfThought(GenerateAnswer)\n",
        "        self.max_docs = max_docs\n",
        "\n",
        "    def retrieve_parent_documents(self, query):\n",
        "        # Use your retriever to fetch parent documents\n",
        "        results = self.retriever.get_relevant_documents(query)\n",
        "        # Format the results as DSPy expects\n",
        "        return [\n",
        "            {\"long_text\": result.page_content, \"metadata\": result.metadata}\n",
        "            for result in results\n",
        "        ]\n",
        "\n",
        "    def forward(self, question, context=None):\n",
        "        context = context or []  # Ensure context is initialized\n",
        "\n",
        "        # Step 1: Generate query from input question and context\n",
        "        query_response = self.generate_query(context=context, question=question)\n",
        "        query = query_response.query\n",
        "\n",
        "        # Step 2: Retrieve parent documents using the generated query\n",
        "        parent_documents = self.retrieve_parent_documents(query)[:self.max_docs]\n",
        "\n",
        "        # Add the retrieved documents to the context\n",
        "        context.extend([doc[\"long_text\"] for doc in parent_documents])\n",
        "\n",
        "        # Step 3: Generate an answer based on the updated context\n",
        "        answer_response = self.generate_answer(context=context, question=question)\n",
        "\n",
        "        return {\n",
        "            \"context\": context,  # Contains parent documents\n",
        "            \"answer\": answer_response.answer,\n",
        "        }\n",
        "\n",
        "# Instantiate ParentDocumentRetriever with your custom retriever\n",
        "parent_doc_retriever = ParentDocumentRetriever(retriever=retriever)\n",
        "\n",
        "# Ensure the inputs are correctly initialized\n",
        "original_query = \"Why few customers gave one star rating to the app?\"  # Example question\n",
        "rag_fusion_context = []  # Initialize as empty if not explicitly provided\n",
        "\n",
        "# Run the ParentDocumentRetriever pipeline\n",
        "output = parent_doc_retriever.forward(question=original_query, context=rag_fusion_context or [])\n",
        "\n",
        "# Display Results\n",
        "print(\"Retrieved Parent Documents Context:\\n\", output[\"context\"])\n",
        "print(\"\\nGenerated Answer:\\n\", output[\"answer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_lC_cb2_h-F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
