{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8660uyxO_V4",
        "outputId": "0f2b9b1a-a826-4b1e-c590-a6350bc5ece4"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain huggingface_hub openai tiktoken pypdf\n",
        "!pip -q install google-generativeai faiss-cpu chromadb unstructured\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install -U FlagEmbedding\n",
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jURZBfa9PVzT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIDEGSxpPmDH",
        "outputId": "0f927998-4ca6-46d2-ac16-ebae8e720e77"
      },
      "outputs": [],
      "source": [
        "# prompt: write code to mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBlozxYfRH8z"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLx-YiuYRR5v"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "\n",
        "## Text Splitting & Docloader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C2LmZfuRXr7",
        "outputId": "a196b25c-bc68-40db-f30b-c92d6a54e2e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -U langchain-huggingface\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqDqqdmyRdBy",
        "outputId": "be0ff162-53cf-4acc-8491-2197ccda1ce8"
      },
      "outputs": [],
      "source": [
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}#for cosine similarity\n",
        "hf = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbd74XTJRhu_"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\n",
        "    \"/content/comments_new.docx_20241223_174156_0000.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfCt5URXR4G1",
        "outputId": "c848beba-ad49-4a4b-dc2d-259cc1b9e0f3"
      },
      "outputs": [],
      "source": [
        "docs = loader.load()\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RtXzjbMSHEy",
        "outputId": "ecf388f9-57b2-4398-a937-7163c5046f4f"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN9KddZFSbcw"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqtrWx30Ive",
        "outputId": "0abe4e4e-709d-4b7c-fe8b-336a28d8cdfb"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-chroma\n",
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwqoaZmlSlBQ"
      },
      "source": [
        "retrieving of complete/full document rather than in chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ22D3ESSjIV"
      },
      "outputs": [],
      "source": [
        "# This text splitter is used to create the child documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"full_documents\", embedding_function=hf\n",
        ")\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()\n",
        "retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itlbJ4JXS3z3"
      },
      "outputs": [],
      "source": [
        "retriever.add_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVuPlFOmS84Q",
        "outputId": "06ffb19a-5e74-49f4-bf74-fe39466b0888"
      },
      "outputs": [],
      "source": [
        "len(list(store.yield_keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4nR6uksTF_q"
      },
      "outputs": [],
      "source": [
        "sub_docs= vectorstore.similarity_search(\"what is the common complaint\",k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTMAnzWNTNz2",
        "outputId": "eaef74e6-782b-44a2-b711-fb46995dc5a2"
      },
      "outputs": [],
      "source": [
        "len(sub_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDBXD4n-TVTG",
        "outputId": "11eb32ce-30b8-4b3e-8842-2bd71ad75b31"
      },
      "outputs": [],
      "source": [
        "print(sub_docs[1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P3gfUddTn1h"
      },
      "outputs": [],
      "source": [
        "rd=retriever.invoke(\"what is the common complaint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1879xVPNTwBH",
        "outputId": "274c288c-ef28-486d-e1be-2576ce4fae18"
      },
      "outputs": [],
      "source": [
        "len(rd[1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QxOabbDT4my",
        "outputId": "452566c9-5e9d-4ec0-f0b2-99dd941b65c2"
      },
      "outputs": [],
      "source": [
        "print(rd[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp5OJwLaUCJx"
      },
      "source": [
        "retrieving larger chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMjFVFTnT6nq"
      },
      "outputs": [],
      "source": [
        "# This text splitter is used to create the parent documents\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "# This text splitter is used to create the child documents\n",
        "# It should create documents smaller than the parent\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"split_parents\", embedding_function=hf\n",
        ")\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1XB6q-QUGUL"
      },
      "outputs": [],
      "source": [
        "chunk_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rImE7W9VUKwB"
      },
      "outputs": [],
      "source": [
        "chunk_retriever.add_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ng21gwUShV",
        "outputId": "7ef7b7fa-12ec-4cb9-e2ed-e1b11151b309"
      },
      "outputs": [],
      "source": [
        "len(list(store.yield_keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-p3JWcMUYZC"
      },
      "outputs": [],
      "source": [
        "sub_docs= vectorstore.similarity_search(\"what is the common complaint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMKa9KlwUfjc",
        "outputId": "161cd914-359a-4c83-ea7d-cbdefdc0ef19"
      },
      "outputs": [],
      "source": [
        "print(sub_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6GXCnr6Uq7y",
        "outputId": "b06e1164-f554-4819-d85c-fbcfe8f310ba"
      },
      "outputs": [],
      "source": [
        "len(sub_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sG976KAUuil"
      },
      "outputs": [],
      "source": [
        "rd=retriever.invoke(\"what is the common complaint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSEcWSAWU5xS",
        "outputId": "e55a9fac-87b0-4741-b2b2-48557b66d953"
      },
      "outputs": [],
      "source": [
        "len(rd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyGl09QUU7x7",
        "outputId": "97aaa57f-01e0-447c-b33a-0028cee35cdc"
      },
      "outputs": [],
      "source": [
        "len(rd[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNtnoavmVA3d",
        "outputId": "e1386652-d2ad-477c-acfb-ad2a85244954"
      },
      "outputs": [],
      "source": [
        "print(rd[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hUUbCboVSBS"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",  # Specify the OpenAI model you wish to use\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=3,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfUM2sBbVYjb"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=chunk_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-PHwDfuVdIV",
        "outputId": "c3d00b6e-0217-4041-b061-34da42448e92"
      },
      "outputs": [],
      "source": [
        "query=\"what is the common complaint\"\n",
        "qa.invoke(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYlxiHHTVoln"
      },
      "source": [
        "dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7opG7rmgVp3M",
        "outputId": "bcd7c755-31ad-4628-d3c6-cf0aa8f02ac9"
      },
      "outputs": [],
      "source": [
        "!pip install -U dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ7sdzCMV9vr"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "from dsp.utils import deduplicate\n",
        "#turbo=dspy.Together(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",api_key=\"6c818e6aeda3d7c5ce440139ecd84a9b25941be08d0ad05e690d5ff8c528c61a\")\n",
        "import dspy\n",
        "lm = dspy.LM('openai/gpt-4o-mini', api_key='sk-proj-dRzfw5ulDRwOAeW24LwXT3BlbkFJAqkZtWMz8qkW3h0fLIwy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_-7WyzVWX0q"
      },
      "outputs": [],
      "source": [
        "retriever=chunk_retriever\n",
        "class ChromaRetriever:\n",
        "    def __init__(self, retriever):\n",
        "        self.retriever = retriever\n",
        "\n",
        "    def __call__(self, query, k=5):\n",
        "        results = self.retriever.get_relevant_documents(query)\n",
        "        # Format results to include a `long_text` attribute\n",
        "        return [\n",
        "            {\"long_text\": result.page_content, \"metadata\": result.metadata}\n",
        "            for result in results\n",
        "        ]\n",
        "\n",
        "# Instantiate your retriever\n",
        "chroma_retriever = ChromaRetriever(retriever)\n",
        "\n",
        "# Configure DSPy to use the ChromaRetriever for RM\n",
        "dspy.configure(lm=lm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwKBG0VgWchl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfvTvtKmW2Mx",
        "outputId": "beb30776-038f-4110-b595-38528d3340fc"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "from dspy import Signature, InputField, OutputField, Module, ChainOfThought\n",
        "\n",
        "class GenerateQuery(Signature):\n",
        "    context = InputField(desc=\"may contain relevant facts\")\n",
        "    question = InputField()\n",
        "    query = OutputField()\n",
        "\n",
        "class GenerateAnswer(Signature):\n",
        "    context = InputField(desc=\"contains parent documents\")\n",
        "    question = InputField()\n",
        "    answer = OutputField(desc=\"a concise and relevant response\")\n",
        "\n",
        "class ParentDocumentRetriever(Module):\n",
        "    def __init__(self, retriever, max_docs=5):\n",
        "        super().__init__()\n",
        "        self.generate_query = ChainOfThought(GenerateQuery)\n",
        "        self.retriever = retriever\n",
        "        self.generate_answer = ChainOfThought(GenerateAnswer)\n",
        "        self.max_docs = max_docs\n",
        "\n",
        "    def retrieve_parent_documents(self, query):\n",
        "        # Use your retriever to fetch parent documents\n",
        "        results = self.retriever.get_relevant_documents(query)\n",
        "        # Format the results as DSPy expects\n",
        "        return [\n",
        "            {\"long_text\": result.page_content, \"metadata\": result.metadata}\n",
        "            for result in results\n",
        "        ]\n",
        "\n",
        "    def forward(self, question, context=None):\n",
        "        context = context or []  # Ensure context is initialized\n",
        "\n",
        "        # Step 1: Generate query from input question and context\n",
        "        query_response = self.generate_query(context=context, question=question)\n",
        "        query = query_response.query\n",
        "\n",
        "        # Step 2: Retrieve parent documents using the generated query\n",
        "        parent_documents = self.retrieve_parent_documents(query)[:self.max_docs]\n",
        "\n",
        "        # Add the retrieved documents to the context\n",
        "        context.extend([doc[\"long_text\"] for doc in parent_documents])\n",
        "\n",
        "        # Step 3: Generate an answer based on the updated context\n",
        "        answer_response = self.generate_answer(context=context, question=question)\n",
        "\n",
        "        return {\n",
        "            \"context\": context,  # Contains parent documents\n",
        "            \"answer\": answer_response.answer,\n",
        "        }\n",
        "\n",
        "# Instantiate ParentDocumentRetriever with your custom retriever\n",
        "parent_doc_retriever = ParentDocumentRetriever(retriever=retriever)\n",
        "\n",
        "# Ensure the inputs are correctly initialized\n",
        "original_query = \"Why few customers gave one star rating to the app?\"  # Example question\n",
        "rag_fusion_context = []  # Initialize as empty if not explicitly provided\n",
        "\n",
        "# Run the ParentDocumentRetriever pipeline\n",
        "output = parent_doc_retriever.forward(question=original_query, context=rag_fusion_context or [])\n",
        "\n",
        "# Display Results\n",
        "print(\"Retrieved Parent Documents Context:\\n\", output[\"context\"])\n",
        "print(\"\\nGenerated Answer:\\n\", output[\"answer\"])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
